{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweepy import Stream\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy.streaming import StreamListener\n",
    "import tweepy\n",
    "import sys\n",
    "import json\n",
    "\n",
    "\n",
    "#New imports\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TWEET_COUNT = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokens for the Tweepy API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckey=\"hpbARu5lJlozST82JEdXYcaS7\"\n",
    "csecret=\"JpfbXATmdNPz6yIhFwmVU1mGU28QTICCuYkfqGibb25HV4x4VK\"\n",
    "atoken=\"1094363214043889665-UohVaHgV89P7OtSgUlWq6QJ6q30Yu1\"\n",
    "asecret=\"mz0RhOmUHN2ISAFcE3j0bOwZVxoAy5x5Ccn8RAiqYrRRI\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweet Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tweetFetcher:\n",
    "    \n",
    "    \n",
    "    def __init__(self, ckey, csecret, atoken, asecret):\n",
    "        \n",
    "        auth = OAuthHandler(ckey, csecret)\n",
    "        auth.set_access_token(atoken, asecret)\n",
    "        self.api = tweepy.API(auth)        \n",
    "        self.actor_list = []\n",
    "    \n",
    "    \n",
    "    #Manage API limit\n",
    "    def limit_handled(self, cursor):\n",
    "        while True:\n",
    "            try:\n",
    "                yield cursor.next()\n",
    "            except tweepy.RateLimitError:\n",
    "                time.sleep(15*60)\n",
    "            except StopIteration:\n",
    "                break\n",
    "    \n",
    "\n",
    "### FUNCTIONS THAT HANDLE ACTOR LIST ###\n",
    "    \n",
    "    def create_actor_list_from_file(self, input_actor_file):\n",
    "        with open(input_actor_file) as actor_file:\n",
    "            actor_list = []\n",
    "            for line in actor_file:\n",
    "                actor_list.append(line.strip())\n",
    "        self.actor_list = actor_list\n",
    "        \n",
    "        \n",
    "    def set_actor_list(self, provided_actor_list):\n",
    "        self.actor_list = provided_actor_list\n",
    "        \n",
    "    def get_actor_list(self):\n",
    "        return self.actor_list\n",
    "\n",
    "    \n",
    "    # assumes actor_list has no duplicates\n",
    "    def run_query(self, output_file):\n",
    "    \n",
    "        with open(output_file, \"w\") as write_file:\n",
    "            for actor in self.actor_list:\n",
    "                tweet_list = []\n",
    "                \n",
    "                \n",
    "                \n",
    "                cursor = tweepy.Cursor(self.api.search, q=actor, lang='en', tweet_mode='extended').items(TWEET_COUNT)\n",
    "                \n",
    "        \n",
    "                for tweet in self.limit_handled(cursor):\n",
    "                    \n",
    "                    #Get the text of the tweet\n",
    "                    \n",
    "                    if hasattr(tweet, 'text'):\n",
    "                        contents = tweet.text\n",
    "                    else:\n",
    "                        contents = tweet.full_text\n",
    "                    \n",
    "                    \n",
    "                    datetime = tweet.created_at\n",
    "                    tweet_tuple = datetime, contents\n",
    "                    tweet_list.append(tweet_tuple)\n",
    "                    \n",
    "                    json.dump(tweet_tuple, write_file, indent=4, sort_keys=True, default=str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example of how to use TweetFetcher\n",
    "\n",
    "\n",
    "def fetch_tweets():\n",
    "    tweet_fetcher = tweetFetcher(ckey, csecret, atoken, asecret)\n",
    "    \n",
    "    tweet_fetcher.create_actor_list_from_file(\"intermediates/test_actors.txt\")\n",
    "    \n",
    "    tweet_fetcher.run_query(\"intermediates/data_file.json\")\n",
    "\n",
    "fetch_tweets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class sentiment_analyzer:\n",
    "    \n",
    "    \n",
    "    #Given a tweet, return the sentiment\n",
    "    def get_tweet_sentiment(self, tweet):\n",
    "        \n",
    "        sentiment = TextBlob(tweet).sentiment\n",
    "        \n",
    "        return sentiment\n",
    "    \n",
    "    \n",
    "    def mass_tweet_analyis(self, archive_file):\n",
    "        \n",
    "        \n",
    "        with open(archive_file) as json_file:  \n",
    "            data = json.load(json_file)\n",
    "            for p in data:\n",
    "                print(p)\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    ##Deprecated Method: Do not USE!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!1111111111111111111111111\n",
    "    \n",
    "    def update_tweet_sentiment(self, actor_tweet_dictionary):\n",
    "    \n",
    "        tweets_by_actor = actor_tweet_dictionary\n",
    "        for actors in tweets_by_actor:\n",
    "            for tweets in (tweets_by_actor[actors]):\n",
    "                tweets.update(sentiment=TextBlob(tweets['content']).sentiment)\n",
    "                print(tweets)\n",
    "            \n",
    "        return(tweets_by_actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analyzer = sentiment_analyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=-0.66875, subjectivity=0.7416666666666667)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_analyzer.get_tweet_sentiment(\"i am a bad dumb stupid idiot loser\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
